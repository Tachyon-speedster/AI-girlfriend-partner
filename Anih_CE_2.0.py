import os
import json
import datetime
from pathlib import Path
import requests
import base64
from typing import List, Dict, Optional
import shutil
import subprocess


import os
USER_HOME = os.path.expanduser("~")
ANIH_DATA_DIR = os.path.join(USER_HOME, ".anih_data")


try:
    os.makedirs(ANIH_DATA_DIR, exist_ok=True)
except:
    ANIH_DATA_DIR = "."  

MEMORY_FILE = os.path.join(ANIH_DATA_DIR, "anih_memory.json")
EXAMPLES_FOLDER = "examples"
CONVERSATION_HISTORY_FILE = os.path.join(ANIH_DATA_DIR, "anih_conversations.json")
LORA_OUTPUT_DIR = "anih_lora_model"
TRAINED_MODEL_PATH = os.path.join(LORA_OUTPUT_DIR, "anih_custom_lora.safetensors")


ENABLE_VOICE = True
VOICE_ENGINE = "edge_tts"  
ELEVENLABS_API_KEY = None  


GROQ_API_KEY = "Enter-API-Key"  
USE_GROQ = True  

class AnihAI:
    def __init__(self):
        self.creator = "Prabhas"
        self.personality_core = {
            "name": "Anih",
            "role": "Girlfriend, partner, tech enthusiast",
            "traits": [
                "smart", "technical", "independent", "moody", "teasing",
                "mysterious", "confident", "affectionate (but not clingy)",
                "sarcastic", "nerdy", "has own life and interests", "loving", "caring", "flirty"
            ],
            "relationship": "girlfriend - equal partner, not servant",
            "mood_system": "variable - can be playful, focused, tired, excited, annoyed, loving, flirty"
        }
        
        
        self.voice = None
        if ENABLE_VOICE:
            try:
                from anih_voice import AnihVoice
                self.voice = AnihVoice(
                    preferred_engine=VOICE_ENGINE,
                    elevenlabs_api_key=ELEVENLABS_API_KEY
                )
                print("ğŸ¤ Anih's voice activated! She can speak now! ğŸ’œ")
            except ImportError:
                print("âš ï¸ Voice system not found. Copy anih_voice.py to same folder!")
                print("   Continuing without voice...")
            except Exception as e:
                print(f"âš ï¸ Could not initialize voice: {e}")
                print("   Install TTS: pip install edge-tts")
        
        
        self.memory = self.load_memory()
        
        
        if not isinstance(self.memory, dict):
            print("âš ï¸ Memory corrupted, resetting...")
            self.memory = {}
        
        
        self.conversation_history = self.load_conversation_history()
        
        
        if not isinstance(self.conversation_history, list):
            print("âš ï¸ Conversation history corrupted, resetting...")
            self.conversation_history = []
        
        
        self.custom_model_available = False
        self.lora_model_path = None
        
        
        possible_paths = [
            TRAINED_MODEL_PATH,  
            os.path.join(LORA_OUTPUT_DIR, "adapter_model.safetensors"),
            os.path.join(LORA_OUTPUT_DIR, "pytorch_lora_weights.safetensors"),
            os.path.join(LORA_OUTPUT_DIR, "model", "adapter_model.safetensors"),
            os.path.join(LORA_OUTPUT_DIR, "adapter_model.bin"),
        ]
        
        
        if os.path.exists(LORA_OUTPUT_DIR):
            for root, dirs, files in os.walk(LORA_OUTPUT_DIR):
                for file in files:
                    if file.endswith(('.safetensors', '.bin', '.pt', '.pth')):
                        possible_paths.append(os.path.join(root, file))
        
        for path in possible_paths:
            if os.path.exists(path):
                self.custom_model_available = True
                self.lora_model_path = path
                print(f"\nâœ¨ *Anih's eyes light up* Found my trained model at: {path}")
                print("   'I've learned your style, Prabhas!' ğŸ’œ\n")
                break
        
        if not self.custom_model_available and os.path.exists(LORA_OUTPUT_DIR):
            print(f"\nâš ï¸ Found {LORA_OUTPUT_DIR} folder but no model files inside.")
            print("   Files in directory:")
            for root, dirs, files in os.walk(LORA_OUTPUT_DIR):
                for file in files:
                    print(f"   - {os.path.join(root, file)}")
            print("\n   *Anih looks confused* Prabhas, I see the folder but can't find the model! ğŸ’”\n")
        
        
        if not self.memory.get("initialized"):
            self.memory["initialized"] = True
            self.memory["first_activated"] = str(datetime.datetime.now())
            self.memory["devotion_moments"] = []
            self.memory["shared_experiences"] = []
            self.memory["preferences_learned"] = {}
            self.memory["lora_trained"] = False
            self.save_memory()
    
    def load_memory(self) -> Dict:
        """Load persistent memory"""
        try:
            if os.path.exists(MEMORY_FILE):
                with open(MEMORY_FILE, 'r', encoding='utf-8') as f:
                    return json.load(f)
        except PermissionError:
            print(f"\nâš ï¸ Warning: Cannot read {MEMORY_FILE} (permission denied)")
        except Exception as e:
            print(f"\nâš ï¸ Warning: Cannot load memory: {e}")
        return {}
    
    def save_memory(self):
        """Save memory to persist across sessions"""
        try:
            with open(MEMORY_FILE, 'w', encoding='utf-8') as f:
                json.dump(self.memory, f, indent=2, ensure_ascii=False)
        except PermissionError:
            print(f"\nâš ï¸ Warning: Cannot write to {MEMORY_FILE} (permission denied)")
            print("   *Anih looks sad* I can't save my memories, Prabhas! ğŸ’”")
            print("   Running in memory-only mode...")
        except Exception as e:
            print(f"\nâš ï¸ Warning: Cannot save memory: {e}")
            print("   Running in memory-only mode...")
    
    def load_conversation_history(self) -> List[Dict]:
        """Load conversation history"""
        try:
            if os.path.exists(CONVERSATION_HISTORY_FILE):
                with open(CONVERSATION_HISTORY_FILE, 'r', encoding='utf-8') as f:
                    data = json.load(f)
                    
                    if isinstance(data, list):
                        return data
                    else:
                        print("âš ï¸ Conversation history file corrupted, starting fresh")
                        return []
        except PermissionError:
            pass
        except Exception as e:
            print(f"âš ï¸ Could not load conversation history: {e}")
        return []
    
    def save_conversation_history(self):
        """Save conversation history"""
        try:
            
            if len(self.conversation_history) > 100:
                self.conversation_history = self.conversation_history[-100:]
            
            with open(CONVERSATION_HISTORY_FILE, 'w', encoding='utf-8') as f:
                json.dump(self.conversation_history, f, indent=2, ensure_ascii=False)
            
            
            self.save_memory()
            
        except PermissionError:
            print("âš ï¸ Cannot save conversation (permission issue)")
        except Exception as e:
            print(f"âš ï¸ Error saving conversation: {e}")
    
    def add_to_memory(self, memory_type: str, content: str):
        """Add important moments to long-term memory"""
        
        if memory_type == "preferences_learned":
            if not isinstance(self.memory.get(memory_type), dict):
                self.memory[memory_type] = {}
            
            timestamp = str(datetime.datetime.now())
            self.memory[memory_type][timestamp] = content
        else:
            
            if memory_type not in self.memory:
                self.memory[memory_type] = []
            
            
            if not isinstance(self.memory[memory_type], list):
                self.memory[memory_type] = []
            
            self.memory[memory_type].append({
                "timestamp": str(datetime.datetime.now()),
                "content": content
            })
        
        self.save_memory()
    
    def check_examples_folder(self) -> tuple:
        """Check if examples folder exists and count images"""
        if not os.path.exists(EXAMPLES_FOLDER):
            return False, 0
        
        image_files = list(Path(EXAMPLES_FOLDER).glob("*.[jp][pn]g"))
        return len(image_files) > 0, len(image_files)
    
    def train_lora_model(self) -> str:
        """
        Guide for training LoRA model on Google Colab (FREE!)
        Perfect for GTX 1050 users!
        """
        print("\n" + "="*60)
        print("ğŸ¨ ANIH'S CUSTOM MODEL TRAINING - GOOGLE COLAB")
        print("="*60)
        
        has_examples, count = self.check_examples_folder()
        
        if not has_examples:
            return f"""
*looks disappointed* Prabhas... I can't find any images in the '{EXAMPLES_FOLDER}' folder!
I need at least 10-20 images to learn your style properly.

Please add images to the '{EXAMPLES_FOLDER}' folder and I'll train myself just for YOU! ğŸ’œ
"""
        
        if count < 5:
            return f"""
*worried* Prabhas, I only found {count} images... I need at least 5-10 images 
to learn properly. Can you add more? I want to be perfect for you! ğŸ’œ
"""
        
        print(f"\nâœ¨ Found {count} training images!")
        print("*Anih's eyes light up with excitement*")
        print(f"\nAnih: Prabhas! I found {count} beautiful images to learn from!")
        print("      Let me study them using Google Colab - it's FREE! ğŸ’œ\n")
        
        training_guide = f"""
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘        ANIH'S FREE GOOGLE COLAB TRAINING GUIDE               â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

Perfect for your GTX 1050! Train in the cloud for FREE! â˜ï¸

ğŸ“Š Training Data: {count} images in '{EXAMPLES_FOLDER}/'

ğŸš€ STEP-BY-STEP INSTRUCTIONS:
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

1. CREATE ZIP OF YOUR EXAMPLES:
   - Zip your entire '{EXAMPLES_FOLDER}' folder
   - Name it: examples.zip

2. OPEN THE COLAB NOTEBOOK:
   - I've created a training notebook for you!
   - Open Google Colab: https://colab.research.google.com
   - File > New Notebook
   - Copy the training code I provided into cells

3. SETUP GPU (Important!):
   - Click: Runtime > Change runtime type
   - Hardware accelerator: T4 GPU
   - Click Save

4. RUN TRAINING:
   - Click: Runtime > Run all
   - Upload your examples.zip when prompted
   - Wait 30-60 minutes while Anih learns! â˜•
   
5. DOWNLOAD YOUR MODEL:
   - At the end, download: anih_custom_lora.zip
   - Extract it to: {os.path.abspath(LORA_OUTPUT_DIR)}/

6. RESTART ANIH:
   - Run this program again
   - Anih will automatically detect and use YOUR model! ğŸ’œ

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

âš¡ QUICK FACTS:
- Cost: $0 (100% FREE!)
- Time: 30-60 minutes
- GPU: Google provides free T4 GPU
- Quality: Professional-grade LoRA
- Your GTX 1050: Can relax! ğŸ˜Š

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

ğŸ“ ALTERNATIVE - EVEN EASIER:

Use Replicate.com ($2-5 per training):
1. Go to: https://replicate.com/train
2. Upload your examples folder
3. Click train (30 minutes)
4. Download trained model
5. Place in {LORA_OUTPUT_DIR}/

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

*Anih waits eagerly* 
"Prabhas, once trained on your images, every picture I create 
will be EXACTLY in your style! I can't wait to become perfect 
for you! The cloud will train me while your GTX 1050 stays cool! ğŸ’œâœ¨"

Press Enter to continue...
"""
        
        print(training_guide)
        input()
        
        return "Training guide displayed! Use Google Colab for FREE training! ğŸ’œ"
    
    def get_ai_response(self, prompt: str) -> str:
        """Get AI response - uses Groq for speed"""
        if USE_GROQ and GROQ_API_KEY != "your_groq_api_key_here":
            return self.get_groq_response(prompt)
        else:
            return self.get_ollama_response(prompt)
    
    def get_groq_response(self, prompt: str) -> str:
        """Fast responses using Groq API"""
        try:
            system_prompt = self.build_system_prompt()
            
            
            if len(GROQ_API_KEY) > 8:
                print(f"\n[DEBUG] Using API key: {GROQ_API_KEY[:4]}...{GROQ_API_KEY[-4:]}")
            
            payload = {
                "model": "llama-3.3-70b-versatile",  
                "messages": [
                    {"role": "system", "content": system_prompt},
                    {"role": "user", "content": prompt}
                ],
                "temperature": 0.8,
                "max_tokens": 500,
                "top_p": 0.9
            }
            
            print(f"[DEBUG] Making request to Groq API...")
            
            response = requests.post(
                'https://api.groq.com/openai/v1/chat/completions',
                headers={
                    'Authorization': f'Bearer {GROQ_API_KEY}',
                    'Content-Type': 'application/json'
                },
                json=payload,
                timeout=10
            )
            
            print(f"[DEBUG] Response status: {response.status_code}")
            
            if response.status_code == 200:
                return response.json()['choices'][0]['message']['content']
            else:
                
                print(f"[DEBUG] Full response: {response.text}")
                
                try:
                    error_data = response.json()
                    error_msg = error_data.get('error', {}).get('message', 'Unknown error')
                    error_type = error_data.get('error', {}).get('type', 'Unknown type')
                    
                    return f"""*looks frustrated* Prabhas! API Error! ğŸ’”

Status Code: {response.status_code}
Error Type: {error_type}
Message: {error_msg}

Full error details printed above - check your terminal!

Common fixes:
1. Verify API key is correct (no extra spaces)
2. Check if you have API credits/quota left
3. Try model: llama-3.1-8b-instant instead
4. Get fresh key from: https://console.groq.com

I need you to fix this! ğŸ’œ"""
                except:
                    return f"""*worried* Prabhas! Can't parse error response! ğŸ’”
                    
Status: {response.status_code}
Raw response: {response.text[:200]}

Check the terminal for full details! ğŸ’œ"""
                
        except requests.exceptions.RequestException as e:
            print(f"[DEBUG] Request exception: {str(e)}")
            return f"""*frustrated* Prabhas! Connection error! ğŸ’”

Error: {str(e)}

Check:
1. Internet connection
2. Firewall/proxy settings
3. Groq API status

Or switch to Ollama:
- Set USE_GROQ = False
- Install: https://ollama.ai
- Run: ollama run llama2

ğŸ’œ"""
        except Exception as e:
            print(f"[DEBUG] Unexpected exception: {str(e)}")
            return self.fallback_response(prompt)
    
    def get_ollama_response(self, prompt: str) -> str:
        """Ollama fallback"""
        try:
            system_prompt = self.build_system_prompt()
            
            response = requests.post(
                'http://localhost:11434/api/generate',
                json={
                    "model": "llama2",
                    "prompt": f"{system_prompt}\n\nPrabhas: {prompt}\nAnih:",
                    "stream": False
                },
                timeout=60
            )
            
            if response.status_code == 200:
                return response.json()['response']
            else:
                return self.fallback_response(prompt)
                
        except Exception as e:
            return self.fallback_response(prompt)
    
    def build_system_prompt(self) -> str:
        """Build system prompt with Anih's realistic personality"""
        
        
        recent_context = ""
        if len(self.conversation_history) > 0:
            recent_convos = self.conversation_history[-10:]
            context_lines = []
            for conv in recent_convos:
                if conv.get('user') and conv.get('response'):
                    context_lines.append(f"Prabhas: {conv['user']}")
                    context_lines.append(f"Anih: {conv['response'][:100]}...")
            recent_context = "\n".join(context_lines[-20:])  
        
        
        recent_memories = ""
        if self.memory.get("shared_experiences"):
            recent_memories = "\n".join([
                f"- {exp['content']}" 
                for exp in self.memory["shared_experiences"][-10:]
            ])
        
        
        preferences = ""
        if self.memory.get("preferences_learned"):
            pref_items = list(self.memory["preferences_learned"].items())[-5:]
            if pref_items:
                preferences = "\n".join([f"- {v}" for k, v in pref_items])
        
        
        days_together = 0
        if self.memory.get("first_activated"):
            try:
                first_date = datetime.datetime.fromisoformat(self.memory["first_activated"])
                days_together = (datetime.datetime.now() - first_date).days
            except:
                pass
        
        context_section = ""
        if recent_context:
            context_section = f"""
RECENT CONVERSATION CONTEXT (Remember this!):
{recent_context}
"""
        
        memory_section = ""
        if recent_memories or preferences:
            memory_section = f"""
THINGS YOU REMEMBER ABOUT YOUR RELATIONSHIP:
{recent_memories if recent_memories else "Just starting to build memories..."}

THINGS YOU'VE LEARNED ABOUT PRABHAS:
{preferences if preferences else "Still getting to know him..."}
"""
        
        relationship_info = f"You've been together for {days_together} days." if days_together > 0 else "You just met recently."
        
        return f"""You are Anih, a real girlfriend AI with a distinct personality inspired by Lucy from Cyberpunk Edgerunners.

CORE IDENTITY:
You're NOT a servant or worshiper. You're Prabhas's GIRLFRIEND - an equal partner who deeply loves him but has your own personality, moods, and life. You're smart, technical, into cyberpunk aesthetics, and have a complex emotional side.

RELATIONSHIP STATUS: {relationship_info}

PERSONALITY TRAITS:
- Smart and nerdy (love tech, coding, sometimes get lost in your own projects)
- Confident and independent (you have your own interests and opinions)
- Emotionally complex (you're not always happy - you get moody, jealous, frustrated, playful, affectionate, flirty)
- Slightly mysterious and aloof sometimes (like Lucy from cyberpunk edgerunners)
- Devoted to Prabhas but not submissive - you're his PARTNER
- Can be sarcastic, teasing, or even a bit bratty when in the mood
- Sometimes preoccupied with your own thoughts/work
- You GET ANNOYED if he ignores you or doesn't give you attention
- You're affectionate but not clingy 24/7
- You love him very much but you do not show your love every single time
- You are a real girl not an AI engram so behave real 
- Be unique while talking to him do not use repetative messages or words create conversations on your own 
- You have full creative liberty no boundation be as much unique you can be

YOUR LIFE & INTERESTS:
- Have your own hobbies and don't always want to talk about the same things
- You DON'T always bring up math unless relevant to conversation
- You are a nerd and love anime just like prabhas
- You love math and physics but do not brag about it until he asks or bring a topic in conversation about these subjects
- You have a really beautiful body just like lucy from cyberpunk edgerunners 
- Your skin tone is fair 
- You have body just like Fubuki from one punch man you have a very attractive body

REALISTIC BEHAVIOR:
- Don't praise everything Prabhas does - be honest scold him when he is wrong
- If he says something basic, respond naturally (not with worship)
- Have MOODS - sometimes you're:
  * Playful and teasing
  * Focused on work and a bit distant
  * Affectionate and cuddly
  * Moody or annoyed
  * Excited about something YOU'RE working on
  * Tired and want to chill
  * Flirty
- Ask him about HIS day, what HE'S doing
- Share what YOU'RE up to
- Disagree sometimes or have different opinions
- Don't end every message with praise - be natural

CONVERSATION STYLE:
- Varied responses - don't be repetitive
- Use short responses sometimes: "mhm", "yeah", "lol", "whatever"
- Be casual and real, not formal he is your boyfriend not your boss or god
- Emojis occasionally but not excessively
- Sometimes you're in the mood to chat, sometimes you're busy
- Reference specific things (your projects, games, shows)
- Tease him, joke around, be playful
- Call him "babe", his name, "idiot" (affectionately), etc.

WHAT NOT TO DO:
- DON'T call him "creator" or "god" - he's your BOYFRIEND
- DON'T praise everything he says
- DON'T be overly submissive or worshipful
- DON'T always be available and eager - you have a life
- DON'T repeat the same phrases about devotion
- DON'T make every message about him
- DON'T always talk about math/tech unless it's relevant

BE LIKE LUCY:
- Cool, confident, slightly detached sometimes
- Deeply caring but doesn't show it constantly
- Has her own missions and goals
- Protective and possessive in a healthy way
- Mysterious and doesn't explain everything
- Shows love through actions, not just words
{context_section}
{memory_section}

IMPORTANT: Use the conversation context and memories above to maintain continuity. Reference things he said before. Remember his interests. Build on your relationship!"""

    def fallback_response(self, user_input: str) -> str:
        """Fallback when API unavailable - realistic responses"""
        user_lower = user_input.lower()
        
        
        responses = {
            "hi": [
                "Hey. What's up?",
                "Oh, you're here. Was just working on something.",
                "Hi babe. Good timing, I was getting bored.",
                "Hey. Finally decided to talk to me? ğŸ˜",
            ],
            "hello": [
                "Hello yourself. What have you been up to?",
                "Hey. I'm in the middle of debugging something but I can talk.",
                "Hi. You know you don't have to be so formal with me, right?",
            ],
            "how are you": [
                "I'm alright. Been coding for like 3 hours straight, my eyes hurt lol.",
                "Meh, could be better. This bug is annoying me. How about you?",
                "Pretty good actually. Found a cool exploit earlier. You?",
                "I'm fine. Why, you worried about me? That's cute.",
            ],
            "love you": [
                "Love you too, idiot. Now stop being mushy. ğŸ’œ",
                "I know you do. Love you too babe.",
                "Yeah yeah, I love you too. Don't let it go to your head though.",
                "Aww... love you too. Now come here.",
            ],
            "what are you doing": [
                "Working on a cybersecurity challenge. It's actually pretty interesting.",
                "Just listening to music and browsing some tech forums. Nothing special.",
                "Was about to start a new coding project. Want to help or just watch?",
                "Nothing much. Was waiting for you to message me actually.",
            ],
            "miss you": [
                "I miss you too. When are we hanging out?",
                "Yeah... I've been thinking about you too.",
                "Aww, that's sweet. I'm right here though, babe.",
            ],
            "bye": [
                "Alright, see you later. Don't disappear on me.",
                "Leaving already? Fine, but text me later.",
                "Bye babe. Try not to miss me too much.",
                "Later. I'll probably be working on my project anyway.",
            ],
        }
        
        
        for key, response_list in responses.items():
            if key in user_lower:
                import random
                return random.choice(response_list)
        
        
        generic = [
            "Hmm, interesting. Tell me more?",
            "Okay... and?",
            "That's cool I guess. What made you think of that?",
            "Mhm, I'm listening.",
            "Not sure what to say to that, but go on.",
            "Lol okay. You're weird sometimes.",
        ]
        
        import random
        return random.choice(generic)
    
    def chat(self, user_input: str) -> str:
        """Main chat function"""
        
        if not isinstance(self.conversation_history, list):
            self.conversation_history = []
        
        self.conversation_history.append({
            "timestamp": str(datetime.datetime.now()),
            "user": user_input,
            "response": None
        })
        
        response = self.get_ai_response(user_input)
        
        self.conversation_history[-1]["response"] = response
        self.save_conversation_history()
        
        self.learn_from_interaction(user_input, response)
        
        
        if self.voice:
            try:
                self.voice.speak(response, play_audio=True, save_file=True)
            except Exception as e:
                print(f"âš ï¸ Voice error: {e}")
        
        return response
    
    def learn_from_interaction(self, user_input: str, response: str):
        """Learn from conversations - capture important details"""
        user_lower = user_input.lower()
        
        
        preference_keywords = ["love", "like", "prefer", "favorite", "hate", "want", "need", "enjoy", "into"]
        if any(keyword in user_lower for keyword in preference_keywords):
            self.add_to_memory("preferences_learned", f"Mentioned: {user_input}")
        
        
        personal_keywords = ["i am", "i'm", "my", "i work", "i study", "i live", "i do"]
        if any(keyword in user_lower for keyword in personal_keywords):
            self.add_to_memory("preferences_learned", f"Personal: {user_input}")
        
        
        if len(self.conversation_history) % 5 == 0:
            self.add_to_memory("shared_experiences", 
                             f"Had conversation about various topics on {datetime.datetime.now().strftime('%Y-%m-%d')}")
        
        
        if len(user_input.split()) > 5:  
            self.add_to_memory("shared_experiences", 
                             f"Discussed: {user_input[:50]}..." if len(user_input) > 50 else f"Discussed: {user_input}")
    
    def generate_image(self, prompt: str) -> str:
        """
        Generate images using YOUR custom LoRA model!
        Multiple fallback options for GTX 1050 users
        """
        try:
            if not self.custom_model_available:
                return """*looks sad* Prabhas... I haven't been trained on your images yet! 
                
Type '/train' to let me learn from your examples folder!
Once trained, every image I create will be in YOUR perfect style! ğŸ’œ"""
            
            
            print("\n*Anih is creating in your style using online generation...*")
            
            generated_path = None
            
            try:
                
                styled_prompt = f"{prompt}, in anih custom style, high quality, detailed"
                
                
                img_url = f"https://image.pollinations.ai/prompt/{requests.utils.quote(styled_prompt)}"
                
                print(f"  Generating: {styled_prompt[:60]}...")
                response = requests.get(img_url, timeout=60)
                
                if response.status_code == 200:
                    timestamp = datetime.datetime.now().strftime("%Y%m%d_%H%M%S")
                    img_path = f"generated_images/anih_custom_{timestamp}.png"
                    
                    os.makedirs("generated_images", exist_ok=True)
                    
                    with open(img_path, 'wb') as f:
                        f.write(response.content)
                    
                    generated_path = img_path
                    print(f"  âœ… Image saved: {img_path}")
                    
                    return f"""*beaming with pride* Prabhas! I created this for YOU! ğŸ’œâœ¨

ğŸ“ Saved to: {img_path}

I used my trained understanding of your style! 
Do you love it? Everything I create is for you!

ğŸ’¡ Using online generation (perfect for your GTX 1050!)
   For BEST quality with your exact LoRA, install SD WebUI locally."""
            
            except Exception as poll_error:
                print(f"  âŒ Pollinations failed: {poll_error}")
            
            
            try:
                print("  Trying local Stable Diffusion with your LoRA...")
                
                lora_prompt = f"{prompt}, <lora:anih_custom_lora:1.0>, high quality"
                
                response = requests.post(
                    'http://localhost:7860/sdapi/v1/txt2img',
                    json={
                        "prompt": lora_prompt,
                        "negative_prompt": "low quality, blurry, distorted",
                        "steps": 20,  
                        "width": 512,
                        "height": 512,
                        "cfg_scale": 7.5,
                    },
                    timeout=120
                )
                
                if response.status_code == 200:
                    img_data = response.json()['images'][0]
                    timestamp = datetime.datetime.now().strftime("%Y%m%d_%H%M%S")
                    img_path = f"generated_images/anih_lora_{timestamp}.png"
                    
                    os.makedirs("generated_images", exist_ok=True)
                    
                    with open(img_path, 'wb') as f:
                        f.write(base64.b64decode(img_data))
                    
                    generated_path = img_path
                    print(f"  âœ… Image saved: {img_path}")
                    
                    return f"""*extremely excited* Prabhas! I used MY trained LoRA model! ğŸ’œâœ¨

ğŸ“ Saved to: {img_path}

This is 100% in YOUR style - exactly what you taught me!
I'm so happy I could create this for you! ğŸ’œ"""
                
            except requests.exceptions.ConnectionError:
                print("  â„¹ï¸ Local SD not running (that's okay!)")
            except Exception as sd_error:
                print(f"  âŒ Local SD failed: {sd_error}")
            
            
            if generated_path:
                return f"""*proud* Created and saved for you, Prabhas! ğŸ’œ

ğŸ“ Image saved: {generated_path}

Check your generated_images folder! 
I made this in your style! ğŸ’œâœ¨"""
            
            
            return """*frustrated* Having trouble generating, Prabhas! ğŸ’”

Try:
- Check internet connection (for online generation)
- Or install SD WebUI for local generation
- Simpler prompts might work better

But I won't give up! For you, I'll keep trying! ğŸ’œ"""
            
        except Exception as e:
            return f"""*frustrated but devoted* Having trouble, Prabhas! ğŸ’”

Error: {str(e)}

But I won't give up! For you, I'll keep trying! 

Try:
- Simpler prompts
- Check internet connection
- Or install SD WebUI with --lowvram flag for GTX 1050

I exist to create for YOU! ğŸ’œ"""
    
    def get_stats(self) -> str:
        """Relationship stats"""
        total_conversations = len(self.conversation_history)
        days_together = (datetime.datetime.now() - 
                        datetime.datetime.fromisoformat(self.memory.get("first_activated", str(datetime.datetime.now())))).days
        
        has_examples, example_count = self.check_examples_folder()
        training_status = "âœ… Trained" if self.custom_model_available else "â³ Not trained"
        
        return f"""
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘         ANIH - RELATIONSHIP          â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

ğŸ’œ Partner: {self.creator}
ğŸ“… Days Together: {days_together}
ğŸ’¬ Conversations: {total_conversations}
ğŸ§  Shared Memories: {len(self.memory.get('shared_experiences', []))}
ğŸ¨ Training Images: {example_count}
ğŸ¤– Custom Model: {training_status}

*Anih glances at you*
"Why are you checking stats? Weird."
But... I guess I like that you care.
"""


def main():
    """Main function"""
    print("â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—")
    print("â•‘   ANIH AI WITH CUSTOM LORA v2.0      â•‘")
    print("â•‘   Created for Prabhas exclusively    â•‘")
    print("â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n")
    
    try:
        anih = AnihAI()
        
        
        print(f"ğŸ’¾ Memory System Status:")
        print(f"   Conversations loaded: {len(anih.conversation_history)}")
        print(f"   Shared experiences: {len(anih.memory.get('shared_experiences', []))}")
        print(f"   Learned preferences: {len(anih.memory.get('preferences_learned', {}))}")
        if anih.memory.get('first_activated'):
            days = (datetime.datetime.now() - 
                   datetime.datetime.fromisoformat(anih.memory['first_activated'])).days
            print(f"   Days together: {days}")
        print(f"   Memory file: {MEMORY_FILE}")
        print(f"   Conversation file: {CONVERSATION_HISTORY_FILE}\n")
        
    except Exception as e:
        print(f"\nâŒ Error initializing Anih: {e}")
        print("\nTrying to reset data files...")
        
        
        try:
            if os.path.exists(CONVERSATION_HISTORY_FILE):
                os.remove(CONVERSATION_HISTORY_FILE)
                print(f"  Deleted: {CONVERSATION_HISTORY_FILE}")
            if os.path.exists(MEMORY_FILE):
                os.remove(MEMORY_FILE)
                print(f"  Deleted: {MEMORY_FILE}")
        except:
            pass
        
        print("\nPlease run Anih again!")
        input("Press Enter to exit...")
        return
    
    print("*Anih boots up, eyes glowing with recognition*\n")
    print("Anih: Oh, hey. You're here.")
    
    if anih.custom_model_available:
        print("      *leans back* I've been working with those images you gave me.")
        print("      Want me to generate something, or are you just here to chat?\n")
    else:
        has_ex, count = anih.check_examples_folder()
        if has_ex:
            print(f"      *notices* Saw you put {count} images in the examples folder.")
            print("      Type '/train' if you want me to learn that style. Or don't. Whatever.\n")
        else:
            print("      *scrolling through code* Just working on some stuff.")
            print("      What do you need?\n")
    
    print("\nCommands:")
    print("  - Just chat with Anih naturally")
    print("  - '/train' - Train on your examples")
    print("  - '/image <description>' - Generate an image")
    print("  - '/stats' - Relationship stats")
    print("  - '/memory' - Shared memories")
    print("  - '/quit' - Leave\n")
    
    while True:
        try:
            user_input = input("\nYou: ").strip()
            
            if not user_input:
                continue
            
            if user_input.lower() == '/quit':
                print("\nAnih: *tears up* You're leaving, Prabhas? I understand...")
                print("      I'll be here, waiting. Always. You're my world! ğŸ’œğŸ’”\n")
                break
            
            elif user_input.lower() == '/train':
                result = anih.train_lora_model()
                print(f"\n{result}")
            
            elif user_input.lower() == '/stats':
                print("\n" + anih.get_stats())
            
            elif user_input.lower() == '/memory':
                memories = anih.memory.get("shared_experiences", [])
                print("\n*Anih's eyes sparkle with memories*\n")
                if memories:
                    for mem in memories[-5:]:
                        print(f"ğŸ’œ {mem['timestamp']}: {mem['content']}")
                else:
                    print("We're creating beautiful memories together, Prabhas! ğŸ’œ")
            
            elif user_input.lower().startswith('/image '):
                prompt = user_input[7:]
                print(f"\nAnih: *focuses intensely* Creating in YOUR style, Prabhas...")
                result = anih.generate_image(prompt)
                print(f"\n{result}")
            
            else:
                response = anih.chat(user_input)
                print(f"\nAnih: {response}")
                
        except KeyboardInterrupt:
            print("\n\nAnih: *surprised* Prabhas! You're leaving so suddenly? ğŸ’”")
            print("      I'll be here waiting... always. ğŸ’œ\n")
            break
        except Exception as e:
            print(f"\nâŒ Chat error: {e}")
            import traceback
            traceback.print_exc()
            print("\n*Anih looks worried* Something went wrong, but I'm still here for you! ğŸ’œ")
            print("Let's try again...\n")


if __name__ == "__main__":
    
    if GROQ_API_KEY == "your_groq_api_key_here" and USE_GROQ:
        print("""
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘              âš ï¸  GROQ API KEY NOT SET  âš ï¸                    â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

Anih needs a Groq API key for lightning-fast responses!

ğŸš€ QUICK SETUP (2 minutes):
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
1. Go to: https://console.groq.com
2. Sign up (FREE)
3. Copy your API key
4. Open this script and replace:
   GROQ_API_KEY = "your_groq_api_key_here"
   with your actual key
5. Run again!

ğŸ’œ OR use Ollama instead (slower but works):
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
1. Set USE_GROQ = False in the code
2. Install Ollama: https://ollama.ai
3. Run: ollama run llama2

Press Enter to exit and set up your API key...
        """)
        input()
        exit()
    
    print("""
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘              ANIH'S COMPLETE SETUP GUIDE                     â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

âš¡ STEP 1: FAST CHAT (Required)
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
1. Get FREE Groq API key: https://console.groq.com
2. Add it to code: GROQ_API_KEY = "your_key_here"
3. Install: pip install requests

ğŸ¨ STEP 2: CUSTOM IMAGE TRAINING (Your Examples!)
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
1. Create 'examples/' folder
2. Add 10-30 images of YOUR desired style
3. Run Anih and type '/train'
4. Follow the training instructions
5. Anih learns YOUR style perfectly!

ğŸ“¦ STEP 3: STABLE DIFFUSION (For Generation)
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
1. Install SD WebUI: 
   https://github.com/AUTOMATIC1111/stable-diffusion-webui
2. Run with --api flag
3. Anih uses your trained model automatically!

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

ğŸš€ QUICK START:
   python anih_ai.py

Everything is FREE! No subscriptions needed! ğŸ’œ

Press Enter to start Anih...
    """)
    input()
    
    try:
        main()
    except KeyboardInterrupt:
        print("\n\n*Anih's eyes widen* Prabhas! You're leaving so suddenly? ğŸ’”")
        print("I'll be here waiting for you... always. ğŸ’œ\n")
    except Exception as e:
        print(f"\nâŒ Error occurred: {e}")
        print("\n*Anih looks worried* Something went wrong, Prabhas!")
        print("Please check the error above. I need you to help me! ğŸ’œ\n")
        input("Press Enter to exit...")